{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297ebda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.half"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from time import time as t\n",
    "\n",
    "from bindsnet.network import *\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.utils import get_square_weights, get_square_assignments\n",
    "from bindsnet.evaluation import (\n",
    "    all_activity,\n",
    "    proportion_weighting,\n",
    "    assign_labels,\n",
    ")\n",
    "\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_input,\n",
    "    plot_spikes,\n",
    "    plot_weights,\n",
    "    plot_assignments,\n",
    "    plot_performance,\n",
    "    plot_voltages,\n",
    ")\n",
    "from pathlib import Path, PurePath\n",
    "\n",
    "\"\"\"\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--seed\", type=int, default=0)\n",
    "parser.add_argument(\"--n_neurons\", type=int, default=100)\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=1)\n",
    "parser.add_argument(\"--n_test\", type=int, default=10000)\n",
    "parser.add_argument(\"--n_train\", type=int, default=60000)\n",
    "parser.add_argument(\"--n_workers\", type=int, default=-1)\n",
    "parser.add_argument(\"--exc\", type=float, default=22.5)\n",
    "parser.add_argument(\"--inh\", type=float, default=120)\n",
    "parser.add_argument(\"--theta_plus\", type=float, default=0.05)\n",
    "parser.add_argument(\"--time\", type=int, default=250)\n",
    "parser.add_argument(\"--dt\", type=int, default=1.0)\n",
    "parser.add_argument(\"--intensity\", type=float, default=128)\n",
    "parser.add_argument(\"--progress_interval\", type=int, default=10)\n",
    "parser.add_argument(\"--update_interval\", type=int, default=250)\n",
    "parser.add_argument(\"--train\", dest=\"train\", action=\"store_true\")\n",
    "parser.add_argument(\"--test\", dest=\"train\", action=\"store_false\")\n",
    "parser.add_argument(\"--plot\", dest=\"plot\", action=\"store_true\")\n",
    "parser.add_argument(\"--gpu\", dest=\"gpu\", action=\"store_true\")\n",
    "parser.set_defaults(plot=True, gpu=False)\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "\n",
    "torch.get_autocast_gpu_dtype()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485265b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = int(0)\n",
    "n_neurons = int(400)\n",
    "n_epochs = int(1)\n",
    "n_test = int(10000)\n",
    "n_train = int(60000)\n",
    "n_workers = int(-1)\n",
    "exc = float(22.5)\n",
    "inh = float(120)\n",
    "theta_plus = float(0.05)\n",
    "time = int(64)\n",
    "dt = int(1.0)\n",
    "intensity = float(128)\n",
    "progress_interval = int(10)\n",
    "update_interval = int(250)\n",
    "train = False\n",
    "plot = False\n",
    "gpu = False\n",
    "\n",
    "PATH_NET_PARAM = '../window' + str( time ) + 'ms/BD'+ str( n_neurons ) + '_' + str( time ) + 'ms/'\n",
    "dirNet = Path( PATH_NET_PARAM )\n",
    "assert dirNet.exists() == True, 'Directory:' + PATH_NET_PARAM + ' not available'\n",
    "\n",
    "# Sets up Gpu use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if gpu and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    torch.manual_seed(seed)\n",
    "    device = \"cpu\"\n",
    "    if gpu:\n",
    "        gpu = False\n",
    "\n",
    "torch.set_num_threads(os.cpu_count() - 1)\n",
    "print(\"Running on Device = \", device)\n",
    "\n",
    "# Determines number of workers to use\n",
    "if n_workers == -1:\n",
    "    n_workers = gpu * 4 * torch.cuda.device_count()\n",
    "\n",
    "if not train:\n",
    "    update_interval = n_test\n",
    "\n",
    "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "start_intensity = intensity\n",
    "\n",
    "# Load MNIST data.\n",
    "test_dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Build network.\n",
    "network = DiehlAndCook2015(\n",
    "    n_inpt=784,\n",
    "    n_neurons=n_neurons,\n",
    "    exc=exc,\n",
    "    inh=inh,\n",
    "    dt=dt,\n",
    "    norm=78.4,\n",
    "    theta_plus=theta_plus,\n",
    "    inpt_shape=(1, 28, 28),\n",
    ")\n",
    "\n",
    "routeNetwork = PATH_NET_PARAM + 'network' + str(n_neurons) + 'N_' + str(time) + 'ms_CPU_.pt'\n",
    "p = Path( routeNetwork )\n",
    "\n",
    "assert p.is_file() == True, \"File: network\" + str(n_neurons) + \"N_\" + str(time) + \"ms_CPU_.pt\"\n",
    "\n",
    "#network = load(routeNetwork)\n",
    "#network.load_state_dict( torch.load( routeNetwork , map_location=\"cpu\") )\n",
    "\n",
    "# Set up monitors for spikes and voltages\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(\n",
    "        network.layers[layer], state_vars=[\"s\"], time=int(time / dt)\n",
    "    )\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "\n",
    "voltages = {}\n",
    "for layer in set(network.layers) - {\"X\"}:\n",
    "    voltages[layer] = Monitor(\n",
    "        network.layers[layer], state_vars=[\"v\"], time=int(time / dt)\n",
    "    )\n",
    "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)\n",
    "\n",
    "# Neuron assignments and spike proportions.\n",
    "n_classes = 10\n",
    "\n",
    "routeAssignemnts = PATH_NET_PARAM + 'assignments' + str(n_neurons) + 'N_' + str(time) + 'ms_CPU_.pt'\n",
    "p = Path( routeAssignemnts )\n",
    "assert p.is_file() == True, \"File not available: assignments\" + str(n_neurons) + \"N_\" + str(time) + \"ms_CPU_.pt\"\n",
    "\n",
    "assignments = torch.load( PATH_NET_PARAM + 'assignments' + str(n_neurons) + 'N_' + str(time) + 'ms_CPU_.pt',\"cpu\")\n",
    "\n",
    "routeProportions = PATH_NET_PARAM + 'assignments' + str(n_neurons) + 'N_' + str(time) + 'ms_CPU_.pt'\n",
    "p = Path( routeAssignemnts )\n",
    "assert p.is_file() == True, \"File not available: proportions\" + str(n_neurons) + \"N_\" + str(time) + \"ms_CPU_.pt\"\n",
    "\n",
    "proportions = torch.load( PATH_NET_PARAM + 'proportions' + str(n_neurons) + 'N_' + str(time) + 'ms_CPU_.pt',\"cpu\")\n",
    "\n",
    "'''\n",
    "inputDataToFile = network.X_to_Ae.w.numpy()\n",
    "filenameData = './SpikingNeuralNetwork/BD/BD400/XeAe.csv'\n",
    "inputDataToFile.tofile( filenameData , sep = ',' )\n",
    "inputDataToFile = network.Ae.theta.numpy()\n",
    "filenameData = './SpikingNeuralNetwork/BD/BD400/theta.csv'\n",
    "inputDataToFile.tofile( filenameData , sep = ',' )\n",
    "inputDataToFile = assignments.numpy()\n",
    "filenameData = './SpikingNeuralNetwork/BD/BD400/assignments.csv'\n",
    "inputDataToFile.tofile( filenameData , sep = ',' )\n",
    "inputDataToFile = proportions.numpy()\n",
    "filenameData = './SpikingNeuralNetwork/BD/BD400/proportions.csv'\n",
    "inputDataToFile.tofile( filenameData , sep = ',' )\n",
    "'''\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": 0, \"proportion\": 0}\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros((1, int(time / dt), n_neurons), device=device)\n",
    "\n",
    "# Train the network.\n",
    "print(\"\\nBegin testing\\n\")\n",
    "network.train(mode=False)\n",
    "start = t()\n",
    "\n",
    "epoch = 1\n",
    "\n",
    "contSample = int(0)\n",
    "\n",
    "pbar = tqdm(total=n_test)\n",
    "for step, batch in enumerate(test_dataset):\n",
    "    if step > n_test:\n",
    "        break\n",
    "    # Get next input sample.\n",
    "    inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
    "    if gpu:\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    # Run the network on the input.\n",
    "    \n",
    "    '''\n",
    "    inputNetwork = inputs['X'][:,0,0,:,:].numpy()\n",
    "    filename_InSamp = './SpikingNeuralNetwork/BD/inputSamples/{0:05d}_inputSpikesPoisson'.format(step+1)+'.csv'\n",
    "    inputNetwork.tofile( filename_InSamp , sep = ',' )\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    print('{0:=>30}'.format(''))\n",
    "    print(\"\\nstep:\" , step+1, \" sample: \", batch['encoded_label'])\n",
    "    print('{0:=>30}'.format(''))\n",
    "    '''\n",
    "    network.run(inputs=inputs, time=time, input_time_dim=1)\n",
    "    \n",
    "    '''\n",
    "    filename_Index = './SpikingNeuralNetwork/BD/inputSamples/vectorIndexresultsBindsnet.csv'\n",
    "    with open( filename_Index , 'a', encoding='utf-8' ) as f:\n",
    "        f.write( '\\n' )\n",
    "    '''\n",
    "    # Add to spikes recording.\n",
    "    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
    "    '''\n",
    "    print(\"\")\n",
    "    print(torch.nonzero( spike_record[0] ))\n",
    "    '''\n",
    "    # Convert the array of labels into a tensor\n",
    "    label_tensor = torch.tensor(batch[\"label\"], device=device)\n",
    "    \n",
    "    \n",
    "    with open( './labelsBindsnetIn_' + str(n_neurons) + 'N_' + str(time) + 'ms_CPU_VIM3.csv', 'a', encoding='utf-8' ) as f:\n",
    "        f.write( str( int(label_tensor) ) +'\\n' )\n",
    "    \n",
    "    \n",
    "    # Get network predictions.\n",
    "    all_activity_pred = all_activity(\n",
    "        spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "    )\n",
    "    proportion_pred = proportion_weighting(\n",
    "        spikes=spike_record,\n",
    "        assignments=assignments,\n",
    "        proportions=proportions,\n",
    "        n_labels=n_classes,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    with open( './labelsBindsnetOut_' + str(n_neurons) + 'N_' + str(time) + 'ms_CPU_VIM3.csv', 'a', encoding='utf-8' ) as f:\n",
    "        f.write( str( int(all_activity_pred) ) +'\\n' )\n",
    "    \n",
    "    \n",
    "    # Compute network accuracy according to available classification strategies.\n",
    "    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\n",
    "    accuracy[\"proportion\"] += float(\n",
    "        torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "    )\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "    pbar.set_description_str(\"Test progress: \")\n",
    "    pbar.update()\n",
    "\n",
    "print(\"\\nAll activity accuracy: %.2f\" % (accuracy[\"all\"] / n_test))\n",
    "print(\"Proportion weighting accuracy: %.2f \\n\" % (accuracy[\"proportion\"] / n_test))\n",
    "\n",
    "\n",
    "print(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\n",
    "print(\"Testing complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41e63b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
